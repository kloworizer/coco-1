{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18278352",
   "metadata": {},
   "source": [
    "# Membuat pipeline untuk inferensi model R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d5947",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-13T05:36:27.295254Z",
     "iopub.status.busy": "2022-07-13T05:36:27.294634Z",
     "iopub.status.idle": "2022-07-13T05:36:59.112891Z",
     "shell.execute_reply": "2022-07-13T05:36:59.111606Z"
    },
    "papermill": {
     "duration": 31.826478,
     "end_time": "2022-07-13T05:36:59.116134",
     "exception": false,
     "start_time": "2022-07-13T05:36:27.289656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python --upgrade\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871cac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T05:36:59.132321Z",
     "iopub.status.busy": "2022-07-13T05:36:59.131621Z",
     "iopub.status.idle": "2022-07-13T05:37:10.021999Z",
     "shell.execute_reply": "2022-07-13T05:37:10.020178Z"
    },
    "papermill": {
     "duration": 10.938968,
     "end_time": "2022-07-13T05:37:10.062389",
     "exception": false,
     "start_time": "2022-07-13T05:36:59.123421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_best = tf.keras.models.load_model('../../models/Esha_R_CNN_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3182f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T05:37:10.079030Z",
     "iopub.status.busy": "2022-07-13T05:37:10.078600Z",
     "iopub.status.idle": "2022-07-13T05:49:57.451656Z",
     "shell.execute_reply": "2022-07-13T05:49:57.450790Z"
    },
    "papermill": {
     "duration": 767.413217,
     "end_time": "2022-07-13T05:49:57.483025",
     "exception": false,
     "start_time": "2022-07-13T05:37:10.069808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "target_size = (224, 224)\n",
    "test_files = tf.io.gfile.glob('../../data/testing_images/*.jpg')\n",
    "\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "used_image_size = (148,308)\n",
    "max_proposed_boxes = 2000\n",
    "\n",
    "samples = random.sample(test_files,9)\n",
    "\n",
    "fig, axes = plt.subplots(3,3,figsize=(16,16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    filename = samples[i].split('\\\\')[-1]\n",
    "    counter = 0\n",
    "    \n",
    "    img = load_img(samples[i])\n",
    "    normalized_img_array = img_to_array(img)\n",
    "    \n",
    "    start_h = used_image_size[0]\n",
    "    end_h = used_image_size[1]\n",
    "    normalized_img_array = normalized_img_array[start_h:end_h,:,:]\n",
    "\n",
    "    ss.setBaseImage(normalized_img_array)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process()\n",
    "\n",
    "    car_boxes = []\n",
    "    probas = []\n",
    "    cars = 0\n",
    "\n",
    "    for (x, y, w, h) in rects:\n",
    "\n",
    "        if counter <= max_proposed_boxes:\n",
    "            counter += 1\n",
    "            filename_box = filename\n",
    "            proposed_box = [x, y, x + w, y + h]\n",
    "\n",
    "            image_array = normalized_img_array[proposed_box[1]:proposed_box[3],proposed_box[0]:proposed_box[2]]\n",
    "            image_array = cv2.resize(image_array,target_size)\n",
    "\n",
    "            predicted = model_best.predict(image_array.reshape(1,target_size[0],target_size[0],3), verbose=0)\n",
    "\n",
    "            if np.argmax(predicted) == 1 and predicted[0][1] >= 0.8:\n",
    "                car_boxes.append([y, x, y + h, x + w])\n",
    "                probas.append(predicted[0][1])\n",
    "\n",
    "    pic = plt.imread(samples[i])\n",
    "    \n",
    "    if len(probas) > 0:\n",
    "        selected_indices = tf.image.non_max_suppression(car_boxes, probas, 100, iou_threshold=0.0)\n",
    "        selected_boxes = tf.gather(car_boxes, selected_indices)\n",
    "        for j in selected_boxes:\n",
    "            ymin, xmin, ymax, xmax = j[0], j[1], j[2], j[3]\n",
    "            ymin, ymax = ymin + start_h, ymax + start_h\n",
    "            rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            axes[i].add_patch(rect)\n",
    "            cars += 1\n",
    "            \n",
    "    title = str(cars) + ' cars found on ' + filename\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].imshow(pic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('coco1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 824.114767,
   "end_time": "2022-07-13T05:50:00.847292",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-13T05:36:16.732525",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a997a9e5a143cb87c83241c574cffea9a0d49157aa96e5cebdd12b51dbe26ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
